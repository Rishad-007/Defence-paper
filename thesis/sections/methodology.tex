\section{Methodology}\label{sec:methodology}
This section details the hybrid analytical framework integrating sequential forecasting, causal effect estimation, and interpretability diagnostics for \VAT{} policy evaluation.

\subsection{Framework Overview}
The pipeline consists of four interconnected layers: (i) data preprocessing and feature generation; (ii) sequence modeling via \LSTM{} networks; (iii) heterogeneous treatment effect estimation using \CF{} and related meta-learners; and (iv) integration logic producing policy counterfactuals and scenario simulations.

\subsection{Notation}
Let $y_t$ denote a macroeconomic outcome (e.g., real GDP growth), $X_t$ the vector of contemporaneous and lagged covariates, and $D_t$ a binary or multi-valued policy indicator encoding \VAT{} status or intensity. Potential outcomes are $(y_t(0), y_t(1))$ under untreated and treated regimes. The target estimands include the Average Treatment Effect (ATE), Conditional Average Treatment Effect (CATE), and dynamic post-intervention response surfaces.

\subsection{Sequence Modeling with LSTM}
\LSTM{} architectures model nonlinear temporal dependencies:
\begin{align}
  f_t &= \sigma(W_f [h_{t-1}, x_t] + b_f), \\
  i_t &= \sigma(W_i [h_{t-1}, x_t] + b_i), \\
  \tilde{c}_t &= \tanh(W_c [h_{t-1}, x_t] + b_c), \\
  c_t &= f_t \odot c_{t-1} + i_t \odot \tilde{c}_t, \\
  o_t &= \sigma(W_o [h_{t-1}, x_t] + b_o), \\
  h_t &= o_t \odot \tanh(c_t),
\end{align}
where $h_t$ encodes latent macro-financial state representations used for downstream causal modeling and forecasting.

\subsection{Causal Forest Estimation}
A \CF{} partitions the covariate space to estimate CATEs by averaging treatment differences across adaptive, honesty-enforced tree structures. Trees split to maximize heterogeneity in treatment effects while preserving unbiasedness via sample-splitting. The estimator aggregates tree-level localized differences:
\begin{equation}
  \hat{\tau}(x) = \sum_{b=1}^B w_b(x) \left( \bar{y}_{b,1} - \bar{y}_{b,0} \right),
\end{equation}
where $w_b(x)$ weights tree $b$ leaves containing $x$.

\subsection{Orthogonalization and Nuisance Adjustment}
To mitigate confounding, nuisance components (propensity scores $e(X)$ and outcome regressions $m_d(X)$) are first estimated using flexible learners. Residualized scores enter the \CF{} stage, implementing a double machine learning (DML) style orthogonalization that reduces sensitivity to regularization and model selection error.

\subsection{Hybrid Integration Strategy}
Latent embeddings $h_t$ from the \LSTM{} are concatenated with engineered macro features to form enriched inputs for effect estimation. This fusion injects dynamic state information into cross-sectional heterogeneity modeling, improving identification of regime-contingent policy responses.

\subsection{Scenario Simulation and Counterfactual Construction}
Counterfactual paths are generated by (i) simulating forecasts under baseline (no-change) and adjusted \VAT{} policies, (ii) applying estimated CATE surfaces to adjust projected outcomes, and (iii) aggregating impacts across horizons to derive welfare and stabilization metrics.

\subsection{Validation and Robustness}
Model reliability is assessed through pre-policy period placebo tests, sensitivity to lag depth, alternative learner substitutions (gradient boosting vs. forests), and stability of CATE rank-orderings across bootstrap resamples.

\subsection{Interpretability and Diagnostics}
We deploy feature importance decompositions, partial dependence profiles, treatment effect stratification (e.g., by inflation regime), and influence diagnostics to surface drivers of heterogeneity and ensure economic plausibility.

\subsection{Implementation}
The framework is implemented using a combination of deep learning libraries and causal inference toolkits. Reproducibility is supported through configuration versioning, deterministic seeds where feasible, and manifest logging of experimental artifacts.

\subsection{Hyperparameter Strategy}
Hyperparameters for \LSTM{} (hidden units, dropout rate, learning rate, sequence length) are tuned via nested rolling validation. Causal forest parameters (number of trees, minimum leaf size, honesty fraction, sample fraction) follow a coarse-to-fine grid. Selection criteria balance out-of-sample MSE reduction and stability of CATE rank ordering.

\subsection{Identification Considerations}
Identification relies on conditional ignorability given the enriched covariate and latent state set, overlap in propensity scores, and temporal ordering (policy indicator lag relative to outcomes in forecast windows). Sensitivity to violations is partially mitigated via orthogonalization and placebo diagnostics.

\subsection{Computational Efficiency}
Pipeline parallelism is achieved by decoupling sequence embedding generation from effect estimation jobs. Intermediate tensors are cached to reduce redundant forward passes. Incremental retraining is applied when new data extend only the tail of the series.

\subsection{Versioning and Reproducibility}
Each experiment logs: Git commit hash, data digest (SHA256), dependency lockfile hash, random seeds, and parameter YAML specification. This supports deterministic replays and auditability of policy simulations.
